{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Link\n",
        "The following section is just for Google Drive mount, in real experiment, please prepare the dataset (you can download from https://github.com/logpai/loghub)"
      ],
      "metadata": {
        "id": "4RcLJZWx7PG3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "738ed222"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08768f9f"
      },
      "source": [
        "After running the cell above and authorizing Google Drive, run the following cell to navigate to your workspace folder named `6953final`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9875199"
      },
      "source": [
        "import os\n",
        "\n",
        "workspace_path = '/content/drive/My Drive/6953final'\n",
        "\n",
        "if os.path.exists(workspace_path):\n",
        "    os.chdir(workspace_path)\n",
        "    print(f'Successfully changed working directory to: {os.getcwd()}')\n",
        "    print('Contents of the folder:')\n",
        "    print(os.listdir('.'))\n",
        "else:\n",
        "    print(f\"Error: The folder '{workspace_path}' was not found. Please ensure it exists in your Google Drive.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the data"
      ],
      "metadata": {
        "id": "SCNweEsh7pNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section loads the preprocessed HDFS log dataset and converts the raw string fields into structured Python lists.\n",
        "The original CSV stores the event sequence and inter-event time intervals as string representations such as \"[E5,E22,E5,...]\" or \"[0.0, 1.0, ...]\". These strings must be parsed into actual lists before they can be used to train a sequential model.\n",
        "\n",
        "We define two helper functions:\n",
        "\n",
        "\n",
        "*   parse_events extracts event template IDs from a comma-separated string and returns a list like [\"E5\", \"E22\", \"E5\", ...].\n",
        "*   parse_timeinterval converts the time-interval field into a list of floats representing the delay between consecutive events.\n",
        "\n",
        "After parsing, the notebook adds two new dataframe columns:\n",
        "\n",
        "\n",
        "*   events – cleaned list of event IDs\n",
        "*   dts_raw – raw inter-event time values (as floats)\n",
        "\n",
        "This ensures that all downstream processing operates on consistent Python data structures rather than string literals.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UhawBSIN8vg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import chain\n",
        "\n",
        "csv_path = os.path.join(\"HDFS_v1\", \"preprocessed\", \"Event_traces.csv\")\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(\"All Records:\", len(df))\n",
        "print(df.head(2))\n"
      ],
      "metadata": {
        "id": "JLjGRpPuqygW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_events(s: str):\n",
        "    \"\"\"\n",
        "    '[E5,E22,E5,...]' -> ['E5', 'E22', 'E5', ...]\n",
        "    \"\"\"\n",
        "    if pd.isna(s):\n",
        "        return []\n",
        "    s = s.strip()\n",
        "    if s.startswith('[') and s.endswith(']'):\n",
        "        s = s[1:-1]\n",
        "    if not s:\n",
        "        return []\n",
        "    tokens = [tok.strip() for tok in s.split(',') if tok.strip()]\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "RDKgkHS-r1dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_timeinterval(s: str):\n",
        "    \"\"\"\n",
        "    '[0.0, 1.0, 0.0, ...]' -> [0.0, 1.0, 0.0, ...]\n",
        "    \"\"\"\n",
        "    if pd.isna(s):\n",
        "        return []\n",
        "    tokens = parse_events(s)\n",
        "    return [float(t) for t in tokens]\n"
      ],
      "metadata": {
        "id": "ObkVOogur3dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"events\"] = df[\"Features\"].apply(parse_events)\n",
        "df[\"dts_raw\"] = df[\"TimeInterval\"].apply(parse_timeinterval)\n",
        "\n"
      ],
      "metadata": {
        "id": "DEfkB-Qjr6rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section ensures that each sequence’s event list and its time-interval list have matching lengths.\n",
        "In the HDFS dataset, a time-interval sequence typically contains one fewer element than the event sequence (because the first event has no preceding timestamp). To fix this, we define:\n",
        "\n",
        "pad_dts_for_seq(events, dts)\n",
        "\n",
        "*   If both lists already match in length, return the time intervals unchanged.\n",
        "*   If the interval list is one item shorter, prepend a 0.0 to represent the first event.\n",
        "*   Otherwise, raise an error indicating misalignment.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e3vBYLyd9bh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_dts_for_seq(events, dts):\n",
        "    if len(dts) == len(events):\n",
        "        return dts\n",
        "    elif len(dts) == len(events) - 1:\n",
        "        return [0.0] + dts\n",
        "    else:\n",
        "        raise ValueError(f\"len(events)={len(events)}, len(dts)={len(dts)}\")\n",
        "\n",
        "df[\"dts\"] = [\n",
        "    pad_dts_for_seq(ev, dt)\n",
        "    for ev, dt in zip(df[\"events\"], df[\"dts_raw\"])\n",
        "]\n",
        "\n",
        "lens = [(len(e), len(d)) for e, d in zip(df[\"events\"], df[\"dts\"])]\n",
        "print(\"len(events), len(dts):\", lens[:5])\n",
        "assert all(le == ld for le, ld in lens), \"Unequal length\"\n"
      ],
      "metadata": {
        "id": "MoUUrRuRsdVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_ID = 0\n",
        "\n",
        "all_events = [f\"E{i}\" for i in range(1, 30)]  # E1..E29\n",
        "print(\"Event types:\", len(all_events), all_events)\n",
        "\n",
        "event2id = {e: i + 1 for i, e in enumerate(all_events)}\n",
        "id2event = {i: e for e, i in event2id.items()}\n"
      ],
      "metadata": {
        "id": "TmytKBY9trYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_event_seq(seq):\n",
        "    return [event2id[e] for e in seq]\n",
        "df[\"event_ids\"] = df[\"events\"].apply(encode_event_seq)\n",
        "print(\"original events:\", df.loc[0, \"events\"][:15])\n",
        "print(\"original event_ids :\", df.loc[0, \"event_ids\"][:15])\n"
      ],
      "metadata": {
        "id": "HrFsc3aXtwJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Event Encoding and Temporal Bucketization\n",
        "\n",
        "After parsing the raw event sequences and time-interval lists, we convert both modalities into model ready numeric formats.\n",
        "First, each event ID is mapped into a contiguous integer index using a vocabulary dictionary. This produces event_ids, a sequence of integers representing the original log templates in a form suitable for embedding layers.\n",
        "\n",
        "Next, we analyze all non-zero time intervals across the dataset to construct a robust quantile-based bucketing scheme. Since log time intervals are typically heavy-tailed, we compute a range of quantiles (e.g., 40%, 70%, 85%, 93%, 97%, 99%, etc.) and use them as boundaries for discretization. Each interval is then clipped to a maximum threshold (HIGH_CLIP) and assigned to a bucket using np.digitize. This transforms the continuous delays into a small set of learned temporal classes that capture coarse-grained execution timing patterns without being overly sensitive to extreme outliers.\n",
        "\n",
        "The resulting time_buckets field contains, for each sequence, a list of bucket indices aligned with event positions. A summary of bucket frequencies is printed to confirm balanced utilization across the dataset. These encoded representations—event IDs and temporal buckets—serve as the joint input features for the Transformer model."
      ],
      "metadata": {
        "id": "MqJcRhU791ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from itertools import chain\n",
        "\n",
        "all_dts = np.array(list(chain.from_iterable(df[\"dts\"])))\n",
        "nonzero_dts = all_dts[all_dts > 0]\n",
        "\n",
        "print(\"25%,50%,75%,90%,99%:\",\n",
        "      np.quantile(nonzero_dts, [0.25, 0.5, 0.75, 0.9, 0.99]))\n",
        "\n",
        "quantile_levels = [0.0, 0.4, 0.7, 0.85, 0.93, 0.97, 0.99, 0.995]\n",
        "quantiles = np.quantile(nonzero_dts, quantile_levels)\n",
        "quantiles = np.unique(quantiles)\n",
        "print(\"quantile :\", quantiles)\n",
        "\n",
        "HIGH_CLIP = quantiles[-1]\n",
        "\n",
        "def bucketize_dt(dt: float) -> int:\n",
        "    \"\"\"\n",
        "    dt = 0      -> bucket 0\n",
        "    0 < dt < q0 -> bucket 1\n",
        "    q0 < dt < q1-> bucket 2\n",
        "    ...\n",
        "    dt > HIGH_CLIP -> bucket n\n",
        "    \"\"\"\n",
        "    if dt <= 0.0:\n",
        "        return 0\n",
        "    dt = min(dt, HIGH_CLIP)\n",
        "    idx = np.digitize(dt, quantiles, right=True)\n",
        "    return int(1 + idx)\n",
        "\n",
        "MAX_BUCKET_ID = 1 + len(quantiles)\n",
        "NUM_BUCKETS   = MAX_BUCKET_ID + 1\n",
        "print(\"time bucket all num:\", NUM_BUCKETS)\n"
      ],
      "metadata": {
        "id": "Jh7tKLTfuisQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"time_buckets\"] = df[\"dts\"].apply(\n",
        "    lambda seq: [bucketize_dt(dt) for dt in seq]\n",
        ")\n",
        "\n",
        "all_buckets = np.array(list(chain.from_iterable(df[\"time_buckets\"])))\n",
        "unique, counts = np.unique(all_buckets, return_counts=True)\n",
        "for b, c in zip(unique, counts):\n",
        "    print(f\"bucket {b}: {c} ({c / len(all_buckets):.3%})\")\n"
      ],
      "metadata": {
        "id": "XUe63w8yv6YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to determine the max sequence length by selecting the 99 percentile of all sequence length"
      ],
      "metadata": {
        "id": "vy5Iixd0-Ei2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "seq_lens = df[\"events\"].map(len)\n",
        "\n",
        "print(seq_lens.describe())\n",
        "print(\"90%,95%,99%:\",\n",
        "      np.quantile(seq_lens, [0.9, 0.95, 0.99]))\n",
        "\n",
        "plt.hist(seq_lens, bins=50)\n",
        "plt.xlabel(\"sequence length\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.title(\"Event sequence length distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pmXwqK84xuGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LEN = int(np.quantile(seq_lens, 0.99))\n",
        "print(\"MAX_SEQ_LEN:\", MAX_SEQ_LEN)"
      ],
      "metadata": {
        "id": "nnrIEJVsx9jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Encoding + PyTorch Dataset Construction\n",
        "This section defines the utilities needed to convert raw event and time-bucket sequences into fixed-length training examples.\n",
        "pad_or_truncate ensures that every sequence fits the model’s maximum length by trimming long traces and padding short ones with special tokens (PAD or IGNORE).\n",
        "The HDFSDataset class then transforms each row into a causal-language-modeling sample:\n",
        "\n",
        "* input_ids contain all event IDs except the last one (prefix).\n",
        "* labels contain the shifted event IDs except the first one (next-token targets).\n",
        "* time_ids align with the prefix to provide temporal features.\n",
        "* attention_mask marks which positions are real tokens versus padding.\n",
        "This dataset structure enables efficient batching and allows the Transformer to compute next-event prediction loss in a causal manner compatible with online inference."
      ],
      "metadata": {
        "id": "SdLYM0tN-ZXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from math import floor\n",
        "\n",
        "IGNORE_INDEX = -100\n",
        "\n",
        "def pad_or_truncate(seq, max_len, pad_value):\n",
        "    \"\"\"\n",
        "    seq: list[int]\n",
        "    \"\"\"\n",
        "    if len(seq) >= max_len:\n",
        "        return seq[:max_len]\n",
        "    return seq + [pad_value] * (max_len - len(seq))\n",
        "\n",
        "class HDFSDataset(Dataset):\n",
        "    def __init__(self, df, max_len):\n",
        "        self.df = df\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        events = row[\"event_ids\"]\n",
        "        tb     = row[\"time_buckets\"]\n",
        "\n",
        "        input_tokens  = events[:-1]\n",
        "        target_tokens = events[1:]\n",
        "        time_tokens   = tb[:-1]\n",
        "\n",
        "        effective_len = len(input_tokens)\n",
        "\n",
        "        input_ids = pad_or_truncate(input_tokens,  self.max_len, PAD_ID)\n",
        "        time_ids  = pad_or_truncate(time_tokens,   self.max_len, 0)\n",
        "        labels    = pad_or_truncate(target_tokens, self.max_len, IGNORE_INDEX)\n",
        "\n",
        "        attn_mask = [1] * min(effective_len, self.max_len) + \\\n",
        "                    [0] * max(0, self.max_len - effective_len)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\":     torch.tensor(input_ids, dtype=torch.long),\n",
        "            \"time_ids\":      torch.tensor(time_ids,  dtype=torch.long),\n",
        "            \"attention_mask\":torch.tensor(attn_mask, dtype=torch.long),\n",
        "            \"labels\":        torch.tensor(labels,    dtype=torch.long),\n",
        "        }\n"
      ],
      "metadata": {
        "id": "7gV3lFUcOwQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/Validation Split and DataLoader Construction\n",
        "\n",
        "This part creates the train/validation split used for model training.\n",
        "Only normal (Success) traces are used, since the model is trained in a self-supervised next-event prediction setting. The dataset is randomly divided into training and validation subsets using an 70/30 split.\n",
        "\n",
        "Afterward, PyTorch DataLoaders are constructed for both partitions, enabling minibatch training with shuffling, multiprocessing data loading, and pinned memory for faster GPU transfer.\n",
        "This setup provides an efficient input pipeline delivering batches of padded event IDs, time-bucket IDs, attention masks, and labels to the model."
      ],
      "metadata": {
        "id": "gqUKv9uL-p7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# small_df = df.sample(n = 50000, random_state=42)\n",
        "success_df = df[df[\"Label\"] == \"Success\"].reset_index(drop=True)\n",
        "fail_df = df[df[\"Label\"] == \"Fail\"].reset_index(drop=True)\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    success_df,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "train_dataset = HDFSDataset(train_df, max_len=MAX_SEQ_LEN)\n",
        "val_dataset   = HDFSDataset(val_df,   max_len=MAX_SEQ_LEN)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE,\n",
        "                          shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "for k, v in batch.items():\n",
        "    print(k, v.shape)\n"
      ],
      "metadata": {
        "id": "1a2y9bLkO5-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Model Skeleton\n",
        "This section defines the core components of the causal Transformer used for next-event prediction in log sequences.\n",
        "The embedding module maps three input channels—event IDs, positional indices, and time-bucket IDs—into a shared hidden space. The HDFSCausalTransformer stacks multiple masked self-attention layers, ensuring each position attends only to its historical context while ignoring padded tokens through a key-padding mask. The model outputs token-level logits through a final linear layer. A dedicated loss function flattens predictions and labels, applies cross-entropy with IGNORE_INDEX masking, and computes token prediction accuracy."
      ],
      "metadata": {
        "id": "6Jl6LOonweY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "VOCAB_SIZE = len(all_events) + 1\n",
        "NUM_TIME_BUCKETS = NUM_BUCKETS\n",
        "\n",
        "print(\"VOCAB_SIZE:\", VOCAB_SIZE)\n",
        "print(\"NUM_TIME_BUCKETS:\", NUM_TIME_BUCKETS)\n",
        "print(\"MAX_SEQ_LEN:\", MAX_SEQ_LEN)"
      ],
      "metadata": {
        "id": "XnTc2vL-wd54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IGONORE_INDEX = -100"
      ],
      "metadata": {
        "id": "QuDC1xO0NHNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HDFSLogEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, num_time_buckets, max_seq_len, d_model=128, dropout=0.1, pad_id=0):\n",
        "        super().__init__()\n",
        "        self.token_embed = nn.Embedding(vocab_size, d_model, padding_idx=pad_id)\n",
        "        self.pos_embed = nn.Embedding(max_seq_len, d_model)\n",
        "        self.time_embed = nn.Embedding(num_time_buckets, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        nn.init.normal_(self.token_embed.weight, mean=0.0, std=0.02)\n",
        "        nn.init.normal_(self.pos_embed.weight, mean=0.0, std=0.02)\n",
        "        nn.init.normal_(self.time_embed.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, input_ids, time_ids):\n",
        "        \"\"\"\n",
        "        input_ids: [batch_size, seq_len]\n",
        "        time_ids:  [batch_size, seq_len]\n",
        "        \"\"\"\n",
        "        B, T = input_ids.shape\n",
        "        device = input_ids.device\n",
        "\n",
        "        pos_ids = torch.arange(T, device=device).unsqueeze(0).expand(B, T)\n",
        "        x = (\n",
        "            self.token_embed(input_ids) +\n",
        "            self.pos_embed(pos_ids) +\n",
        "            self.time_embed(time_ids)\n",
        "        )\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "DMCQJvUZy0DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HDFSCausalTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        num_time_buckets: int,\n",
        "        max_seq_len: int,\n",
        "        d_model: int = 128,\n",
        "        n_heads: int = 4,\n",
        "        n_layers: int = 3,\n",
        "        d_ff: int = 512,\n",
        "        dropout: float = 0.1,\n",
        "        pad_id: int = 0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_time_buckets = num_time_buckets\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.pad_id = pad_id\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Three type of embedding, will be mixed\n",
        "        self.token_embed = nn.Embedding(vocab_size, d_model, padding_idx=pad_id)\n",
        "        self.pos_embed   = nn.Embedding(max_seq_len, d_model)\n",
        "        self.time_embed  = nn.Embedding(num_time_buckets, d_model)\n",
        "\n",
        "        self.embed_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=d_ff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "            activation=\"gelu\",\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        self.lm_head = nn.Linear(d_model, vocab_size, bias=False)\n",
        "\n",
        "        causal_mask = torch.triu(\n",
        "            torch.ones(max_seq_len, max_seq_len, dtype=torch.bool),\n",
        "            diagonal=1\n",
        "        )\n",
        "        self.register_buffer(\"causal_mask\", causal_mask, persistent=False)\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        nn.init.normal_(self.token_embed.weight, mean=0.0, std=0.02)\n",
        "        nn.init.normal_(self.pos_embed.weight,   mean=0.0, std=0.02)\n",
        "        nn.init.normal_(self.time_embed.weight,  mean=0.0, std=0.02)\n",
        "        nn.init.normal_(self.lm_head.weight,     mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.Tensor,\n",
        "        time_ids: torch.Tensor,\n",
        "        attention_mask: torch.Tensor,\n",
        "    ):\n",
        "        B, T = input_ids.shape\n",
        "        device = input_ids.device\n",
        "\n",
        "        pos_ids = torch.arange(T, device=device).unsqueeze(0).expand(B, T)\n",
        "\n",
        "        tok_emb  = self.token_embed(input_ids)\n",
        "        pos_emb  = self.pos_embed(pos_ids)\n",
        "        time_emb = self.time_embed(time_ids)\n",
        "\n",
        "        x = tok_emb + pos_emb + time_emb\n",
        "        x = self.embed_dropout(x)\n",
        "\n",
        "        causal_mask = self.causal_mask[:T, :T]\n",
        "\n",
        "        key_padding_mask = (attention_mask == 0)\n",
        "\n",
        "        enc_out = self.encoder(\n",
        "            x,\n",
        "            mask=causal_mask,\n",
        "            src_key_padding_mask=key_padding_mask,\n",
        "        )\n",
        "\n",
        "        logits = self.lm_head(enc_out)\n",
        "        return logits\n",
        "\n",
        "    def compute_loss(self, batch):\n",
        "        logits = self(\n",
        "            batch[\"input_ids\"],\n",
        "            batch[\"time_ids\"],\n",
        "            batch[\"attention_mask\"],\n",
        "        )\n",
        "\n",
        "        B, T, V = logits.shape\n",
        "        logits_flat = logits.reshape(B * T, V)\n",
        "        labels_flat = batch[\"labels\"].reshape(B * T)\n",
        "\n",
        "        loss = F.cross_entropy(\n",
        "            logits_flat,\n",
        "            labels_flat,\n",
        "            ignore_index=IGNORE_INDEX,\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = logits_flat.argmax(dim=-1)\n",
        "            mask = labels_flat != IGNORE_INDEX\n",
        "            correct = (pred == labels_flat) & mask\n",
        "            total = mask.sum().item() if mask.any() else 1\n",
        "            acc = correct.sum().item() / total\n",
        "\n",
        "        return loss, acc\n"
      ],
      "metadata": {
        "id": "HGXsXRlIJ5qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = HDFSCausalTransformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_time_buckets=NUM_TIME_BUCKETS,\n",
        "    max_seq_len=MAX_SEQ_LEN,\n",
        "    d_model=128,\n",
        "    n_heads=4,\n",
        "    n_layers=3,\n",
        "    d_ff=512,\n",
        "    dropout=0.1,\n",
        "    pad_id=PAD_ID,\n",
        ").to(device)\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "loss, acc = model.compute_loss(batch)\n",
        "print(\"sanity loss:\", float(loss.item()), \"acc:\", acc)\n"
      ],
      "metadata": {
        "id": "1rxDDIKVLc8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "EPOCHS = 3\n",
        "LR = 1e-3\n",
        "optimizer = AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "train_step_offset = 0\n",
        "val_step_offset = 0\n",
        "\n",
        "history = {\n",
        "    \"train_steps\": [],\n",
        "    \"train_loss\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_steps\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_acc\": [],\n",
        "}\n",
        "\n",
        "def run_epoch(model, dataloader, optimizer=None, history=None, phase=\"train\", max_points=40, global_step_offset=0):\n",
        "    if optimizer is None:\n",
        "        model.eval()\n",
        "        mode = \"eval\"\n",
        "    else:\n",
        "        model.train()\n",
        "        mode = \"train\"\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_tokens = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    num_batches = len(dataloader)\n",
        "    log_interval = max(1, num_batches // max_points)\n",
        "\n",
        "    pbar = tqdm(enumerate(dataloader), total=num_batches, desc=f\"{phase}\", leave=False)\n",
        "\n",
        "    for batch_idx, batch in pbar:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        if optimizer is not None:\n",
        "            optimizer.zero_grad()\n",
        "        loss, acc = model.compute_loss(batch)\n",
        "        if optimizer is not None:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        labels = batch[\"labels\"]\n",
        "        num_tokens = (labels != IGNORE_INDEX).sum().item()\n",
        "        total_loss += loss.item() * num_tokens\n",
        "        total_tokens += num_tokens\n",
        "        total_correct += acc * num_tokens\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            \"loss\": f\"{loss.item():.4f}\",\n",
        "            \"acc\": f\"{acc:.4f}\"\n",
        "        })\n",
        "\n",
        "        if history is not None and (batch_idx % log_interval == 0):\n",
        "            step = global_step_offset + batch_idx\n",
        "            if phase == \"train\":\n",
        "                history[\"train_steps\"].append(step)\n",
        "                history[\"train_loss\"].append(loss.item())\n",
        "                history[\"train_acc\"].append(acc)\n",
        "            else:\n",
        "                history[\"val_steps\"].append(step)\n",
        "                history[\"val_loss\"].append(loss.item())\n",
        "                history[\"val_acc\"].append(acc)\n",
        "\n",
        "    avg_loss = total_loss / max(1, total_tokens)\n",
        "    avg_acc = total_correct / max(1, total_tokens)\n",
        "    last_step = global_step_offset + num_batches\n",
        "    return avg_loss, avg_acc, last_step\n",
        "\n",
        "# for epoch in range(1, EPOCHS + 1):\n",
        "#     train_loss, train_acc = run_epoch(model, train_loader, optimizer)\n",
        "#     val_loss, val_acc = run_epoch(model, val_loader, optimizer=None)\n",
        "\n",
        "#     print(f\"[Epoch {epoch}] \"\n",
        "#         f\"train_loss={train_loss:.4f}, train_acc={train_acc:.4f} | \"\n",
        "#         f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, train_acc, train_step_offset = run_epoch(\n",
        "        model, train_loader, optimizer, history=history,\n",
        "        phase=\"train\", max_points=40, global_step_offset=train_step_offset\n",
        "    )\n",
        "\n",
        "    val_loss, val_acc, val_step_offset = run_epoch(\n",
        "        model, val_loader, optimizer=None, history=history,\n",
        "        phase=\"val\", max_points=40, global_step_offset=val_step_offset\n",
        "    )\n",
        "    print(f\"[Epoch {epoch}] \"\n",
        "          f\"train_loss={train_loss:.4f}, train_acc={train_acc:.4f} | \"\n",
        "          f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "DP-uQmAUQIjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and load the mode\n",
        "Please modify the save path for further using"
      ],
      "metadata": {
        "id": "3oH8ss92_0MR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/6953final/hdfs_transformer.pt\"\n",
        "\n",
        "torch.save({\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"vocab\": id2event,\n",
        "    \"event2id\": event2id,\n",
        "    \"MAX_SEQ_LEN\": MAX_SEQ_LEN,\n",
        "    \"NUM_BUCKETS\": NUM_BUCKETS\n",
        "}, save_path)\n",
        "\n",
        "print(\"Model saved to\", save_path)\n"
      ],
      "metadata": {
        "id": "0VAdIHb7CuG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/6953final/hdfs_transformer.pt\"\n",
        "\n",
        "ckpt = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "id2event = ckpt[\"vocab\"]\n",
        "event2id = ckpt[\"event2id\"]\n",
        "MAX_SEQ_LEN = ckpt[\"MAX_SEQ_LEN\"]\n",
        "NUM_BUCKETS = ckpt[\"NUM_BUCKETS\"]\n",
        "\n",
        "model = HDFSCausalTransformer(\n",
        "    vocab_size=len(id2event) + 1,\n",
        "    time_bucket_size=NUM_BUCKETS,\n",
        "    max_seq_len=MAX_SEQ_LEN,\n",
        "    d_model=128,\n",
        "    n_heads=4,\n",
        "    num_layers=3,\n",
        "    d_ff=512,\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(ckpt[\"model_state\"])\n",
        "\n",
        "model.eval()\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "cS1lMHigC00z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot the trends of Accuracy and Loss"
      ],
      "metadata": {
        "id": "25XB0_Rd_6Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history[\"train_steps\"], history[\"train_loss\"], label=\"train_loss\")\n",
        "plt.plot(history[\"val_steps\"],   history[\"val_loss\"],   label=\"val_loss\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss over training steps\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history[\"train_steps\"], history[\"train_acc\"], label=\"train_acc\")\n",
        "plt.plot(history[\"val_steps\"],   history[\"val_acc\"],   label=\"val_acc\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy over training steps\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "duoS8PF3XR61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Analysis: Simple Predictive Heuristics\n",
        "The first block of code computes how often the next event in a sequence is identical to the current one. This gives a “same-as-previous” accuracy, reflecting how frequently logs simply repeat events.\n",
        "\n",
        "The second block builds bigram transition statistics by counting how often each event is followed by every possible next event. For each event type, it records the probability of the most frequent successor, and averages these probabilities over all event types. This represents how well a simple bigram lookup table could predict the next token.\n",
        "\n",
        "These two measurements provide reference baselines for next-event prediction. Compared with these simple heuristics, the Transformer model achieves substantially higher accuracy, confirming that it captures richer structural patterns in the logs than basic repetition or pairwise event frequencies."
      ],
      "metadata": {
        "id": "yalNXOfdAGDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for seq in df[\"event_ids\"].head(20000):\n",
        "    for i in range(len(seq) - 1):\n",
        "        cur = seq[i]\n",
        "        nxt = seq[i+1]\n",
        "        if nxt == cur:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "\n",
        "print(\"same-as-prev baseline acc:\", correct / total)\n"
      ],
      "metadata": {
        "id": "PPOatTCwSpSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict\n",
        "\n",
        "pair_count = defaultdict(Counter)\n",
        "\n",
        "for seq in df[\"event_ids\"].head(20000):\n",
        "    for i in range(len(seq) - 1):\n",
        "        cur = seq[i]\n",
        "        nxt = seq[i+1]\n",
        "        pair_count[cur][nxt] += 1\n",
        "\n",
        "probs = []\n",
        "for cur, ctr in pair_count.items():\n",
        "    total = sum(ctr.values())\n",
        "    best = ctr.most_common(1)[0][1] / total\n",
        "    probs.append(best)\n",
        "\n",
        "print(\"average bigram:\", sum(probs) / len(probs))\n"
      ],
      "metadata": {
        "id": "ZYm_uUhjSucb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Online Scoring\n",
        "This is just a milestone for recording, please do not use this version"
      ],
      "metadata": {
        "id": "vXStCkRLcaNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def score_sequence(\n",
        "        event_ids,\n",
        "        time_buckets,\n",
        "        model,\n",
        "        id2event,\n",
        "        max_seq_len=MAX_SEQ_LEN,\n",
        "        top_k=5,\n",
        "):\n",
        "    model.eval()\n",
        "    L = len(event_ids)\n",
        "    if L < 2:\n",
        "        raise ValueError(\"sequence too short (len < 2)\")\n",
        "\n",
        "    L_eff = min(L - 1, max_seq_len)\n",
        "\n",
        "    input_ids = event_ids[:L_eff]\n",
        "    time_ids = time_buckets[:L_eff]\n",
        "    next_ids = event_ids[1:L_eff + 1]\n",
        "\n",
        "    input_ids_tensor = torch.tensor(input_ids, dtype=torch.long, device=device).unsqueeze(0)\n",
        "    time_ids_tensor  = torch.tensor(time_ids,  dtype=torch.long, device=device).unsqueeze(0)\n",
        "    attn_mask_tensor = torch.ones_like(input_ids_tensor, dtype=torch.long, device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids_tensor, time_ids_tensor, attn_mask_tensor)  # (1, T, V)\n",
        "        probs  = F.softmax(logits, dim=-1)\n",
        "\n",
        "    probs = probs[0]\n",
        "    T = probs.size(0)\n",
        "\n",
        "    results = {\n",
        "        \"position\": [],\n",
        "        \"true_event_id\": [],\n",
        "        \"true_event_str\": [],\n",
        "        \"prob_true\": [],\n",
        "        \"surprisal\": [],\n",
        "        \"rank\": [],\n",
        "        \"in_top_k\": [],\n",
        "    }\n",
        "\n",
        "    for t in range(T):\n",
        "        true_id = next_ids[t]\n",
        "        prob_vec = probs[t]\n",
        "        prob_true = float(prob_vec[true_id].item())\n",
        "\n",
        "        eps = 1e-12\n",
        "        surprisal = -float(torch.log(torch.tensor(prob_true + eps)))\n",
        "\n",
        "        rank = int((prob_vec > prob_true).sum().item() + 1)\n",
        "\n",
        "        results[\"position\"].append(t + 1)\n",
        "        results[\"true_event_id\"].append(true_id)\n",
        "        results[\"true_event_str\"].append(id2event.get(true_id, f\"ID{true_id}\"))\n",
        "        results[\"prob_true\"].append(prob_true)\n",
        "        results[\"surprisal\"].append(surprisal)\n",
        "        results[\"rank\"].append(rank)\n",
        "        results[\"in_top_k\"].append(rank <= top_k)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "N4kXaxWpcb3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# row = df.iloc[2]\n",
        "row = fail_df.iloc[0]\n",
        "\n",
        "event_ids    = row[\"event_ids\"]\n",
        "time_buckets = row[\"time_buckets\"]\n",
        "\n",
        "print(event_ids)\n",
        "print(time_buckets)\n",
        "print(len(event_ids))\n",
        "\n",
        "res = score_sequence(\n",
        "    event_ids=event_ids,\n",
        "    time_buckets=time_buckets,\n",
        "    model=model,\n",
        "    id2event=id2event,\n",
        "    max_seq_len=MAX_SEQ_LEN,\n",
        "    top_k=5,\n",
        ")\n",
        "\n",
        "for i in range(31):\n",
        "    print(\n",
        "        f\"t={res['position'][i]:2d} \"\n",
        "        f\"true={res['true_event_str'][i]:>3s} \"\n",
        "        f\"prob={res['prob_true'][i]:.4f} \"\n",
        "        f\"surprisal={res['surprisal'][i]:.3f} \"\n",
        "        f\"rank={res['rank'][i]} \"\n",
        "        f\"in_top5={res['in_top_k'][i]}\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "x7i0_H6_eEZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sliding Window Sequence Scoring\n",
        "To compute a surprisal-based anomaly score for each event, the model must be evaluated in an online fashion—only past events can be used to predict the next one. Since many log sequences exceed the model’s maximum input length, a sliding-window prefix is required to provide a bounded context at every position.\n",
        "\n",
        "The function performs this per-step evaluation.\n",
        "For each position t, it extracts the valid prefix window, feeds it into the model, and obtains the predicted probability distribution for the next event. From this distribution, it derives several key diagnostics: the probability assigned to the true next event, its surprisal (negative log-probability), its rank among all candidate events, and whether it falls within the top-k predictions.\n",
        "\n",
        "By sliding across the entire sequence, the function produces a trajectory of surprisal scores and ranks that reflects how well each event conforms to normal execution patterns. These scores serve as the foundation for online anomaly detection and early-warning visualization."
      ],
      "metadata": {
        "id": "Iejo0H8_AqzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score_sequence_sliding(event_ids, time_buckets, model, id2event, top_k=5):\n",
        "    model.eval()\n",
        "    L = len(event_ids)\n",
        "\n",
        "    results = {\n",
        "        \"position\": [],\n",
        "        \"true_event_id\": [],\n",
        "        \"true_event_str\": [],\n",
        "        \"prob_true\": [],\n",
        "        \"surprisal\": [],\n",
        "        \"rank\": [],\n",
        "        \"in_top_k\": [],\n",
        "    }\n",
        "\n",
        "    if L < 2:\n",
        "        return results\n",
        "    for t in range(1, L):\n",
        "        start = max(0, t - MAX_SEQ_LEN)\n",
        "        prefix_ids = event_ids[start:t]\n",
        "        prefix_times = time_buckets[start:t]\n",
        "\n",
        "        input_ids_tensor = torch.tensor(prefix_ids, dtype=torch.long, device=device).unsqueeze(0)\n",
        "        time_ids_tensor  = torch.tensor(prefix_times, dtype=torch.long, device=device).unsqueeze(0)\n",
        "        attn_mask_tensor = torch.ones_like(input_ids_tensor, dtype=torch.long, device=device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_ids_tensor, time_ids_tensor, attn_mask_tensor)\n",
        "            probs = F.softmax(logits, dim=-1)[0]\n",
        "\n",
        "        prob_vec = probs[-1]\n",
        "        true_id = event_ids[t]\n",
        "\n",
        "        prob_true = float(prob_vec[true_id].item())\n",
        "        eps = 1e-12\n",
        "        surprisal = -float(torch.log(torch.tensor(prob_true + eps)))\n",
        "        rank = int((prob_vec > prob_true).sum().item() + 1)\n",
        "\n",
        "        results[\"position\"].append(t)\n",
        "        results[\"true_event_id\"].append(true_id)\n",
        "        results[\"true_event_str\"].append(id2event.get(true_id, f\"ID{true_id}\"))\n",
        "        results[\"prob_true\"].append(prob_true)\n",
        "        results[\"surprisal\"].append(surprisal)\n",
        "        results[\"rank\"].append(rank)\n",
        "        results[\"in_top_k\"].append(rank <= top_k)\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "qaFDIsVBobga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To turn token level surprisals into an interpretable anomaly signal, we need first aggreagtes them along the sequence\n",
        "compute_prefix_scores takes the per-step surprisal trace and computes two trajectories:\n",
        "\n",
        "\n",
        "*   prefix_mean – the running average surprisal up to each position, reflecting how abnormal the sequence has been on average so far\n",
        "*   prefix_max – the running maximum surprisal, capturing the strongest single deviation seen so far.\n",
        "\n",
        "plot_anomaly_curve then visualizes these two curves over event positions, producing a 1-D “anomaly timeline” for a single trace. This makes it easy to see when the model first becomes surprised, how strong the spike is, and whether anomalies are transient or sustained—information that is crucial for debugging and for reasoning about early-warning behavior.\n",
        "\n"
      ],
      "metadata": {
        "id": "5RozghmXEgtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compute_prefix_scores(sliding_res):\n",
        "    s = np.array(sliding_res[\"surprisal\"], dtype=float)\n",
        "\n",
        "    if s.size == 0:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    prefix_mean = np.cumsum(s) / np.arange(1, len(s) + 1)\n",
        "    prefix_max = np.maximum.accumulate(s)\n",
        "\n",
        "    return prefix_mean, prefix_max\n",
        "\n",
        "\n",
        "def plot_anomaly_curve(sliding_res, title=\"\"):\n",
        "    prefix_mean, prefix_max = compute_prefix_scores(sliding_res)\n",
        "    positions = sliding_res[\"position\"]\n",
        "\n",
        "    if len(positions) == 0:\n",
        "        print(\"No points to plot for this sequence.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(positions, prefix_mean, marker=\"o\", label=\"prefix_mean_surprisal\")\n",
        "    plt.plot(positions, prefix_max,  marker=\"x\", label=\"prefix_max_surprisal\", alpha=0.7)\n",
        "    plt.xlabel(\"Position (t)\")\n",
        "    plt.ylabel(\"Anomaly score\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "sOqVxxdxoxS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row = fail_df.iloc[173]\n",
        "\n",
        "event_ids    = row[\"event_ids\"]\n",
        "time_buckets = row[\"time_buckets\"]\n",
        "res_fail = score_sequence_sliding(event_ids, time_buckets, model, id2event, top_k=5)\n",
        "plot_anomaly_curve(res_fail, title=\"Fail example - prefix anomaly curve\")\n"
      ],
      "metadata": {
        "id": "s7oMVOYOpZQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_final_score(sliding_res, mode=\"mean\"):\n",
        "    prefix_mean, prefix_max = compute_prefix_scores(sliding_res)\n",
        "    if mode == \"mean\":\n",
        "        return float(prefix_mean[-1])\n",
        "    elif mode == \"max\":\n",
        "        return float(prefix_max[-1])\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown mode: {mode}\")\n"
      ],
      "metadata": {
        "id": "ulhrpDPTqNJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_first_crossing(sliding_res, tau, use=\"mean\"):\n",
        "    \"\"\"\n",
        "    tau: abnormal threshold\n",
        "    use: \"mean\" -> prefix_mean_surprisal\n",
        "         \"max\"  -> prefix_max_surprisal\n",
        "    return:\n",
        "      det_pos: first exceed tau position: t，if normal return None\n",
        "    \"\"\"\n",
        "    prefix_mean, prefix_max = compute_prefix_scores(sliding_res)\n",
        "    scores = prefix_mean if use == \"mean\" else prefix_max\n",
        "\n",
        "    for i, s in enumerate(scores):\n",
        "        if s > tau:\n",
        "            return sliding_res[\"position\"][i]\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "ukPHS9rCqPqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test tau, we will calculate the real tau among larger dataset"
      ],
      "metadata": {
        "id": "Jv-XGTv2Ew24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tau = 1.0\n",
        "\n",
        "det_pos = detect_first_crossing(res_fail, tau, use=\"mean\")\n",
        "print(\"first detection pos:\", det_pos)\n"
      ],
      "metadata": {
        "id": "foclIbqEqSwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to estimates an anomaly detection threshold by analyzing a large sammple of normal (success) sequences. A subset of up to 50,000 success traces is selected, and each is scored using the sliding-window surprisal function. For every sequence, the final mean surprisal is computed as a single anomaly score summarizing its normality.\n",
        "\n",
        "Collecting all success scores builds an empirical distribution of “normal” surprisal values. The 95th percentile of this distribution is then chosen as the threshold τ. This data-driven quantile threshold ensures that, under normal behavior, only a small controlled fraction of sequences exceed τ, providing a principled false-positive bound without relying on labeled anomaly data.\n",
        "\n",
        "***This block will take a lot of time, you can use the calculated value for tau below***"
      ],
      "metadata": {
        "id": "tTB-CW8IFi9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"success_df:\", len(success_df))\n",
        "print(\"fail_df:\", len(fail_df))\n",
        "\n",
        "N_SUCCESS_EVAL = 50000\n",
        "num_succ = len(success_df)\n",
        "\n",
        "if num_succ > N_SUCCESS_EVAL:\n",
        "    eval_indices = np.random.choice(num_succ, size=N_SUCCESS_EVAL, replace=False)\n",
        "else:\n",
        "    eval_indices = np.arange(num_succ)\n",
        "\n",
        "success_scores = []\n",
        "\n",
        "for i in eval_indices:\n",
        "    row = success_df.iloc[i]\n",
        "    event_ids = row[\"event_ids\"]\n",
        "    time_buckets = row[\"time_buckets\"]\n",
        "\n",
        "    sliding_res = score_sequence_sliding(event_ids, time_buckets, model, id2event, top_k=5)\n",
        "\n",
        "    if len(sliding_res[\"surprisal\"]) == 0:\n",
        "        continue\n",
        "\n",
        "    score = sequence_final_score(sliding_res, mode=\"mean\")\n",
        "    success_scores.append(score)\n",
        "\n",
        "success_scores = np.array(success_scores)\n",
        "\n",
        "print(\"used success samples:\", success_scores.shape[0])\n",
        "print(\"success_scores stats: mean=%.4f, std=%.4f\" %\n",
        "      (success_scores.mean(), success_scores.std()))\n",
        "\n",
        "tau = np.quantile(success_scores, 0.95)\n",
        "print(\"Chosen tau (95% quantile):\", tau)\n"
      ],
      "metadata": {
        "id": "ETtt12xLt2XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tau obtained from 50,000 success record"
      ],
      "metadata": {
        "id": "wQwmBgrSLr7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tau = 0.4460372090290396"
      ],
      "metadata": {
        "id": "UwAbIBtVLkWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Set\n",
        "Code below this section is for evaluate the peroformance of the model, including FPR, Accuracy, ROC, CDF"
      ],
      "metadata": {
        "id": "_d_WM2f12DXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_fail_set(fail_df, model, id2event, tau, use=\"mean\"):\n",
        "    total = len(fail_df)\n",
        "    detected = 0\n",
        "    advances = []\n",
        "\n",
        "    for idx in range(total):\n",
        "        row = fail_df.iloc[idx]\n",
        "        event_ids    = row[\"event_ids\"]\n",
        "        time_buckets = row[\"time_buckets\"]\n",
        "        L = len(event_ids)\n",
        "\n",
        "        if L < 2:\n",
        "            continue\n",
        "\n",
        "        sliding_res = score_sequence_sliding(event_ids, time_buckets, model, id2event)\n",
        "\n",
        "        det_pos = detect_first_crossing(sliding_res, tau, use=use)\n",
        "\n",
        "        if det_pos is not None:\n",
        "            detected += 1\n",
        "            advances.append((L - det_pos) / L)\n",
        "\n",
        "    recall = detected / total\n",
        "    avg_advance = np.mean(advances) if advances else 0.0\n",
        "\n",
        "    print(f\"FAIL set: total={total}, detected={detected}\")\n",
        "    print(f\"Recall rate: {recall:.4f}\")\n",
        "    print(f\"Average advance ratio: {avg_advance:.4f}\")\n",
        "\n",
        "    return recall, avg_advance"
      ],
      "metadata": {
        "id": "QJ6POQ422C_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_success_fpr(success_df, model, id2event, tau, sample_size=2000, use=\"mean\"):\n",
        "    N = min(len(success_df), sample_size)\n",
        "    idxs = np.random.choice(len(success_df), size=N, replace=False)\n",
        "\n",
        "    false_positives = 0\n",
        "    for idx in idxs:\n",
        "        row = success_df.iloc[idx]\n",
        "        event_ids = row[\"event_ids\"]\n",
        "        time_buckets = row[\"time_buckets\"]\n",
        "\n",
        "        if len(event_ids) < 2:\n",
        "            continue\n",
        "\n",
        "        sliding_res = score_sequence_sliding(event_ids, time_buckets, model, id2event, top_k=5)\n",
        "\n",
        "        det_pos = detect_first_crossing(sliding_res, tau, use=use)\n",
        "        if det_pos is not None:\n",
        "            false_positives += 1\n",
        "    fpr = false_positives / N\n",
        "    print(f\"SUCCESS set FPR: {fpr:.4f}  ({false_positives}/{N})\")\n",
        "\n",
        "    return fpr"
      ],
      "metadata": {
        "id": "wPw7nYzV2zNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall, avg_adv = evaluate_fail_set(\n",
        "    fail_df, model, id2event, tau, use=\"mean\"\n",
        ")\n",
        "\n",
        "fpr = evaluate_success_fpr(\n",
        "    success_df, model, id2event, tau, sample_size=2000, use=\"mean\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "zwrMIApV3bhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_SUCCESS_EVAL = 5000\n",
        "N_FAIL_EVAL = 5000\n",
        "\n",
        "num_succ = len(success_df)\n",
        "num_fail = len(fail_df)\n",
        "\n",
        "succ_indices = np.random.choice(num_succ, size=min(N_SUCCESS_EVAL, num_succ), replace=False)\n",
        "fail_indices = np.random.choice(num_fail, size=min(N_FAIL_EVAL, num_fail), replace=False)\n",
        "\n",
        "success_scores = []\n",
        "fail_scores = []\n",
        "\n",
        "print(\"Scoring success samples...\")\n",
        "for i in tqdm(succ_indices):\n",
        "    row = success_df.iloc[i]\n",
        "    event_ids = row[\"event_ids\"]\n",
        "    time_buckets = row[\"time_buckets\"]\n",
        "\n",
        "    if len(event_ids) < 2:\n",
        "        continue\n",
        "    sliding_res = score_sequence_sliding(event_ids, time_buckets, model, id2event)\n",
        "    if len(sliding_res[\"surprisal\"]) == 0:\n",
        "        continue\n",
        "    score = sequence_final_score(sliding_res, mode=\"mean\")\n",
        "    success_scores.append(score)\n",
        "\n",
        "success_scores = np.array(success_scores)\n",
        "\n",
        "print(\"Scoring fail samples...\")\n",
        "for i in tqdm(fail_indices):\n",
        "    row = fail_df.iloc[i]\n",
        "    event_ids = row[\"event_ids\"]\n",
        "    time_buckets = row[\"time_buckets\"]\n",
        "\n",
        "    if len(event_ids) < 2:\n",
        "        continue\n",
        "\n",
        "    sliding_res = score_sequence_sliding(event_ids, time_buckets, model, id2event)\n",
        "    if len(sliding_res[\"surprisal\"]) == 0:\n",
        "        continue\n",
        "\n",
        "    score = sequence_final_score(sliding_res, mode=\"mean\")\n",
        "    fail_scores.append(score)\n",
        "\n",
        "fail_scores = np.array(fail_scores)\n",
        "print(\"success_scores:\", success_scores.shape, \"fail_scores:\", fail_scores.shape)\n",
        "print(\"success mean/std:\", success_scores.mean(), success_scores.std())\n",
        "print(\"fail mean/std:\", fail_scores.mean(), fail_scores.std())"
      ],
      "metadata": {
        "id": "he9Vjio5L5vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compute_roc_points(success_scores, fail_scores, num_thresholds=100):\n",
        "    all_scores = np.concatenate([success_scores, fail_scores])\n",
        "\n",
        "    qs = np.linspace(0.01, 0.99, num_thresholds)\n",
        "    taus = np.quantile(all_scores, qs)\n",
        "\n",
        "    tprs = []\n",
        "    fprs = []\n",
        "    for tau in taus:\n",
        "        tpr = np.mean(fail_scores > tau)\n",
        "        fpr = np.mean(success_scores > tau)\n",
        "        tprs.append(tpr)\n",
        "        fprs.append(fpr)\n",
        "    return np.array(fprs), np.array(tprs), taus\n",
        "\n",
        "fprs, tprs, taus = compute_roc_points(success_scores, fail_scores, num_thresholds=100)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(fprs, tprs, marker=\"o\", linewidth=1)\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"ROC-like curve (score = avg surprisal)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "try:\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    y_true = np.concatenate([np.zeros_like(success_scores), np.ones_like(fail_scores)])\n",
        "    y_score = np.concatenate([success_scores, fail_scores])\n",
        "    auc = roc_auc_score(y_true, y_score)\n",
        "    print(\"AUC:\", auc)\n",
        "except ImportError:\n",
        "    print(\"sklearn.metrics.roc_auc_score not available\")"
      ],
      "metadata": {
        "id": "wO--JjV6NGp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "bins = 50\n",
        "\n",
        "plt.hist(success_scores, bins=bins, alpha=0.6, label=\"Success\", density=True)\n",
        "plt.hist(fail_scores,    bins=bins, alpha=0.6, label=\"Fail\",    density=True)\n",
        "\n",
        "plt.xlabel(\"Final mean surprisal\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.title(\"Score distribution: Success vs Fail\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PlEOG6SPODS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cdf(data, label):\n",
        "    xs = np.sort(data)\n",
        "    ys = np.linspace(0, 1, len(xs), endpoint=False)\n",
        "    plt.plot(xs, ys, label=label)\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plot_cdf(success_scores, \"Success\")\n",
        "plot_cdf(fail_scores, \"Fail\")\n",
        "plt.xlabel(\"Final mean surprisal\")\n",
        "plt.ylabel(\"CDF\")\n",
        "plt.title(\"CDF of Scores\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VpAGyuSjOFbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_succ = np.random.randint(len(success_df))\n",
        "row_succ = success_df.iloc[idx_succ]\n",
        "succ_events    = row_succ[\"event_ids\"]\n",
        "succ_time_buck = row_succ[\"time_buckets\"]\n",
        "\n",
        "sliding_succ = score_sequence_sliding(succ_events, succ_time_buck, model, id2event)\n",
        "print(\"Random success idx:\", idx_succ, \"len:\", len(succ_events))\n",
        "plot_anomaly_curve(sliding_succ, title=f\"Success example (idx={idx_succ})\")\n"
      ],
      "metadata": {
        "id": "m3f36mpgOIUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_fail = np.random.randint(len(fail_df))\n",
        "row_fail = fail_df.iloc[idx_fail]\n",
        "fail_events    = row_fail[\"event_ids\"]\n",
        "fail_time_buck = row_fail[\"time_buckets\"]\n",
        "\n",
        "sliding_fail = score_sequence_sliding(fail_events, fail_time_buck, model, id2event)\n",
        "print(\"Random fail idx:\", idx_fail, \"len:\", len(fail_events))\n",
        "plot_anomaly_curve(sliding_fail, title=f\"Fail example (idx={idx_fail})\")\n"
      ],
      "metadata": {
        "id": "7dNyuRXDOLY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "succ_best_idx = np.argmin(success_scores)\n",
        "succ_row = success_df.iloc[succ_indices[succ_best_idx]]\n",
        "\n",
        "sliding_succ_best = score_sequence_sliding(\n",
        "    succ_row[\"event_ids\"],\n",
        "    succ_row[\"time_buckets\"],\n",
        "    model,\n",
        "    id2event\n",
        ")\n",
        "plot_anomaly_curve(sliding_succ_best, title=\"Most normal success (lowest score)\")\n",
        "\n",
        "fail_worst_idx = np.argmax(fail_scores)\n",
        "fail_row = fail_df.iloc[fail_indices[fail_worst_idx]]\n",
        "\n",
        "sliding_fail_worst = score_sequence_sliding(\n",
        "    fail_row[\"event_ids\"],\n",
        "    fail_row[\"time_buckets\"],\n",
        "    model,\n",
        "    id2event\n",
        ")\n",
        "plot_anomaly_curve(sliding_fail_worst, title=\"Most abnormal fail (highest score)\")\n"
      ],
      "metadata": {
        "id": "K_r68TB8OQCP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}